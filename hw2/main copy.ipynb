{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_dir):\n",
    "\n",
    "    # Define the image file extensions to be read\n",
    "    img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "    # Initialize an empty list to store the images\n",
    "    images = []\n",
    "\n",
    "    # Loop through all the files in the directory\n",
    "    for file in sorted(os.listdir(img_dir)):\n",
    "        # Check if the file has a valid image extension\n",
    "        if file.lower().endswith(img_exts):\n",
    "            # Read the image using OpenCV\n",
    "            img = cv2.imread(os.path.join(img_dir, file))\n",
    "            # # Convert the image to grayscale and append it to the list\n",
    "            # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "            \n",
    "\n",
    "    # Convert the list of images to a 2D numpy array\n",
    "    img_array = np.array(images)\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cylindrical_warp(img_array, f):\n",
    "\n",
    "    proj_images = []\n",
    "\n",
    "    for img in img_array:\n",
    "        # Get the dimensions of each image\n",
    "        # height, width, channels = img.shape\n",
    "        height, width, channel = img.shape\n",
    "        # Define the center of the cylindrical coordinates\n",
    "        x0 = width // 2\n",
    "        y0 = height // 2\n",
    "\n",
    "        \n",
    "\n",
    "        # Create a new image with the same size as the original image\n",
    "        proj_img = np.zeros_like(img)\n",
    "        # Iterate over each pixel in the new image\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                b=img[i,j,0]\n",
    "                g=img[i,j,1]\n",
    "                r=img[i,j,2]\n",
    "                # Convert the pixel's (x, y) coordinates to cylindrical coordinates (h, theta)\n",
    "                x = j - x0\n",
    "                y = i - y0\n",
    "\n",
    "                h = y/math.sqrt(x**2 + f**2)\n",
    "                theta = math.atan(x / f)\n",
    "\n",
    "                # Calculate the new (x, y) coordinates from the cylindrical coordinates using the inverse transform\n",
    "                \n",
    "                x_new = f*theta + x0\n",
    "                y_new = f*h + y0\n",
    "\n",
    "                # Round the new (x, y) coordinates to the nearest integer to get the corresponding pixel in the original image\n",
    "                x_new_rd = int(round(x_new))\n",
    "                y_new_rd = int(round(y_new))\n",
    "\n",
    "                proj_img[y_new_rd, x_new_rd, 0] = b\n",
    "                proj_img[y_new_rd, x_new_rd, 1] = g\n",
    "                proj_img[y_new_rd, x_new_rd, 2] = r\n",
    "\n",
    "\n",
    "        proj_images.append(proj_img)\n",
    "\n",
    "    proj_array = np.array(proj_images)\n",
    "\n",
    "    # cv.imshow(\"proj_img0\", proj_array[0])\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "\n",
    "    return proj_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_detection(img):\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the derivatives of the image intensity in the x and y directions\n",
    "    dx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Compute the element-wise product of the derivative images\n",
    "    Ix2 = dx * dx\n",
    "    Iy2 = dy * dy\n",
    "    Ixy = dx * dy\n",
    "\n",
    "    # Apply a Gaussian filter to each of the derivative images\n",
    "    ksize = (5, 5)\n",
    "    sigma = 1.0\n",
    "    Ix2 = cv2.GaussianBlur(Ix2, ksize, sigma)\n",
    "    Iy2 = cv2.GaussianBlur(Iy2, ksize, sigma)\n",
    "    Ixy = cv2.GaussianBlur(Ixy, ksize, sigma)\n",
    "\n",
    "    # Compute the sums of the products of derivatives at each pixel using a sliding window\n",
    "    w_size = 5\n",
    "    offset = w_size // 2\n",
    "    height, width = gray.shape\n",
    "    Sxx = np.zeros_like(gray, dtype=np.float32)\n",
    "    Syy = np.zeros_like(gray, dtype=np.float32)\n",
    "    Sxy = np.zeros_like(gray, dtype=np.float32)\n",
    "\n",
    "    for y in range(offset, height - offset):\n",
    "        for x in range(offset, width - offset):\n",
    "            Sxx[y, x] = np.sum(Ix2[y - offset:y + offset + 1, x - offset:x + offset + 1])\n",
    "            Syy[y, x] = np.sum(Iy2[y - offset:y + offset + 1, x - offset:x + offset + 1])\n",
    "            Sxy[y, x] = np.sum(Ixy[y - offset:y + offset + 1, x - offset:x + offset + 1])\n",
    "\n",
    "    # Compute the determinant and trace of the structure tensor\n",
    "    det = (Sxx * Syy) - (Sxy ** 2)\n",
    "    trace = Sxx + Syy\n",
    "\n",
    "    # Compute the corner response function\n",
    "    k = 0.04\n",
    "    response = det - k * (trace ** 2)\n",
    "\n",
    "    # Threshold the corner response function\n",
    "    threshold = 0.01 * response.max()\n",
    "    corners = np.argwhere(response > threshold)\n",
    "\n",
    "    # Draw crosses at the detected corners on the image\n",
    "    for corner in corners:\n",
    "        x, y = corner\n",
    "        size = 1\n",
    "        color = (0, 0, 255)\n",
    "        cv2.line(img, (y - size, x), (y + size, x), color, 2)\n",
    "        cv2.line(img, (y, x - size), (y, x + size), color, 2)\n",
    "\n",
    "    # Show the image with detected corners\n",
    "    cv2.imshow(\"Corners Detected\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def harris_corner_detection(image, block_size=3, ksize=3, k=0.04, threshold=0.06):\n",
    "    # Convert the input image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the derivatives of the image using the Sobel operator\n",
    "    Ix = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    Iy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "\n",
    "    # Compute the products of derivatives at each pixel\n",
    "    Ix2 = Ix ** 2\n",
    "    Iy2 = Iy ** 2\n",
    "    Ixy = Ix * Iy\n",
    "\n",
    "    # Compute the sum of products of derivatives over a local window\n",
    "    if ksize % 2 == 0 or ksize < 1:\n",
    "        raise ValueError(\"Invalid ksize parameter.\")\n",
    "    Sx2 = cv2.boxFilter(Ix2, cv2.CV_64F, (ksize, ksize))\n",
    "    Sy2 = cv2.boxFilter(Iy2, cv2.CV_64F, (ksize, ksize))\n",
    "    Sxy = cv2.boxFilter(Ixy, cv2.CV_64F, (ksize, ksize))\n",
    "\n",
    "    # Compute the Harris response for each pixel\n",
    "    det = (Sx2 * Sy2) - (Sxy ** 2)\n",
    "    trace = Sx2 + Sy2\n",
    "    response = det - k * (trace ** 2)\n",
    "\n",
    "    # Threshold the response to obtain candidate corners\n",
    "    response[response < threshold * response.max()] = 0\n",
    "\n",
    "    # Find the coordinates of the remaining corners\n",
    "    coords = np.argwhere(response > 0)\n",
    "    coords = [tuple(coord[::-1]) for coord in coords]\n",
    "\n",
    "    # Draw circles around the detected corners\n",
    "    for corner in coords:\n",
    "        cv2.circle(image, corner, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display the image with detected corners\n",
    "    cv2.imshow('Harris Corner Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_descriptor(img, corners):\n",
    "    patch_size = 16\n",
    "    subregion_size = 8\n",
    "    num_bins = 8\n",
    "    eps = 1e-5\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = gray.shape\n",
    "\n",
    "    # Compute the gradient magnitude and orientation for the entire image\n",
    "    dx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    mag = np.sqrt(dx**2 + dy**2)\n",
    "    ang = np.arctan2(dy, dx)\n",
    "\n",
    "    descriptors = []\n",
    "    for corner in corners:\n",
    "        x, y = corner\n",
    "\n",
    "        # Extract the patch centered at the corner point\n",
    "        x1 = max(0, x - patch_size//2)\n",
    "        x2 = min(width-1, x + patch_size//2)\n",
    "        y1 = max(0, y - patch_size//2)\n",
    "        y2 = min(height-1, y + patch_size//2)\n",
    "        patch = mag[y1:y2, x1:x2]\n",
    "        patch_ang = ang[y1:y2, x1:x2]\n",
    "\n",
    "        # Divide the patch into subregions and compute histograms of gradient orientations\n",
    "        desc = []\n",
    "        for i in range(patch.shape[0]//subregion_size):\n",
    "            for j in range(patch.shape[1]//subregion_size):\n",
    "                subpatch = patch[i*subregion_size:(i+1)*subregion_size, j*subregion_size:(j+1)*subregion_size]\n",
    "                subpatch_ang = patch_ang[i*subregion_size:(i+1)*subregion_size, j*subregion_size:(j+1)*subregion_size]\n",
    "                hist, _ = np.histogram(subpatch_ang, bins=num_bins, range=(-np.pi, np.pi), weights=subpatch)\n",
    "                desc.extend(hist)\n",
    "        \n",
    "        # Normalize the descriptor to be invariant to changes in illumination, contrast, and scale\n",
    "        desc = np.array(desc)\n",
    "        desc = desc / (np.linalg.norm(desc) + eps)\n",
    "\n",
    "        descriptors.append(desc)\n",
    "    #print(descriptors[0])\n",
    "\n",
    "    return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(desc1, desc2, threshold=0.5):\n",
    "    matches = []\n",
    "    for i, d1 in enumerate(desc1):\n",
    "        best_match = None\n",
    "        best_distance = float('inf')\n",
    "        for j, d2 in enumerate(desc2):\n",
    "            distance = 0\n",
    "            for k in range(min(len(d1), len(d2))):\n",
    "                distance += np.sum((d1[k] - d2[k]) ** 2)\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = j\n",
    "        if best_distance < threshold:\n",
    "            matches.append((i, best_match))\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_and_warp_images(img1, features1, img2, features2, matches):\n",
    "    # Convert feature point data to NumPy arrays\n",
    "    src_pts = np.float32([features1[m[0]] for m in matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([features2[m[1]] for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    matched_img = np.hstack((img1, img2))\n",
    "\n",
    "    for m in matches:\n",
    "        pt1 = tuple(map(int, features1[m[0]]))\n",
    "        pt2 = tuple(map(int, features2[m[1]]))\n",
    "        cv2.line(matched_img, pt1, (pt2[0] + img1.shape[1], pt2[1]), (0, 255, 0), 1)\n",
    "\n",
    "    # for kp in features1:\n",
    "    #     cv2.circle(img1, tuple(kp), 2, 255, -1)\n",
    "    # for kp in features2:\n",
    "    #     cv2.circle(img2, tuple(kp), 2, 255, -1)\n",
    "    # matched_img = np.hstack((img1, img2))\n",
    "\n",
    "\n",
    "    # Compute homography matrix\n",
    "    # H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # # Warp image using homography\n",
    "    # warped_img = cv2.warpPerspective(img1, H, img2.shape[::-1])\n",
    "\n",
    "    return matched_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    img_array = read_images(\"test_images\")\n",
    "    proj_array = cylindrical_warp(img_array, 900)\n",
    "    corners0 = harris_corner_detection(proj_array[0])\n",
    "    corners1 = harris_corner_detection(proj_array[1])\n",
    "    descriptors0 = feature_descriptor(proj_array[0], corners0)\n",
    "    descriptors1 = feature_descriptor(proj_array[1], corners1)\n",
    "    matches = feature_matching(descriptors0, descriptors1)\n",
    "\n",
    "    mathced_img = match_and_warp_images(proj_array[0], corners0, proj_array[1], corners1, matches)\n",
    "    cv2.imshow('mathed_img', mathced_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    # cv2.imshow('wapred_img', wapred_img)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
