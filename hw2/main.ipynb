{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_dir):\n",
    "\n",
    "    # Define the image file extensions to be read\n",
    "    img_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "    # Initialize an empty list to store the images\n",
    "    images = []\n",
    "\n",
    "    # Loop through all the files in the directory\n",
    "    for file in sorted(os.listdir(img_dir)):\n",
    "        # Check if the file has a valid image extension\n",
    "        if file.lower().endswith(img_exts):\n",
    "            # Read the image using OpenCV\n",
    "            img = cv2.imread(os.path.join(img_dir, file))\n",
    "            # # Convert the image to grayscale and append it to the list\n",
    "            # gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "            \n",
    "\n",
    "    # Convert the list of images to a 2D numpy array\n",
    "    img_array = np.array(images)\n",
    "\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cylindrical_warp(img_array, f):\n",
    "\n",
    "    proj_images = []\n",
    "\n",
    "    for img in img_array:\n",
    "        # Get the dimensions of each image\n",
    "        # height, width, channels = img.shape\n",
    "        height, width, channel = img.shape\n",
    "        # Define the center of the cylindrical coordinates\n",
    "        x0 = width // 2\n",
    "        y0 = height // 2\n",
    "\n",
    "        \n",
    "\n",
    "        # Create a new image with the same size as the original image\n",
    "        proj_img = np.zeros_like(img)\n",
    "        # Iterate over each pixel in the new image\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                b=img[i,j,0]\n",
    "                g=img[i,j,1]\n",
    "                r=img[i,j,2]\n",
    "                # Convert the pixel's (x, y) coordinates to cylindrical coordinates (h, theta)\n",
    "                x = j - x0\n",
    "                y = i - y0\n",
    "\n",
    "                h = y/math.sqrt(x**2 + f**2)\n",
    "                theta = math.atan(x / f)\n",
    "\n",
    "                # Calculate the new (x, y) coordinates from the cylindrical coordinates using the inverse transform\n",
    "                \n",
    "                x_new = f*theta + x0\n",
    "                y_new = f*h + y0\n",
    "\n",
    "                # Round the new (x, y) coordinates to the nearest integer to get the corresponding pixel in the original image\n",
    "                x_new_rd = int(round(x_new))\n",
    "                y_new_rd = int(round(y_new))\n",
    "\n",
    "                proj_img[y_new_rd, x_new_rd, 0] = b\n",
    "                proj_img[y_new_rd, x_new_rd, 1] = g\n",
    "                proj_img[y_new_rd, x_new_rd, 2] = r\n",
    "\n",
    "\n",
    "        proj_images.append(proj_img)\n",
    "\n",
    "    proj_array = np.array(proj_images)\n",
    "\n",
    "    # cv.imshow(\"proj_img0\", proj_array[0])\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "\n",
    "    return proj_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_detection(img):\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Compute the derivatives of the image intensity in the x and y directions\n",
    "    dx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Compute the element-wise product of the derivative images\n",
    "    Ix2 = dx * dx\n",
    "    Iy2 = dy * dy\n",
    "    Ixy = dx * dy\n",
    "\n",
    "    # Apply a Gaussian filter to each of the derivative images\n",
    "    ksize = (5, 5)\n",
    "    sigma = 1.0\n",
    "    Ix2 = cv2.GaussianBlur(Ix2, ksize, sigma)\n",
    "    Iy2 = cv2.GaussianBlur(Iy2, ksize, sigma)\n",
    "    Ixy = cv2.GaussianBlur(Ixy, ksize, sigma)\n",
    "\n",
    "    # Compute the sums of the products of derivatives at each pixel using a sliding window\n",
    "    w_size = 5\n",
    "    offset = w_size // 2\n",
    "    height, width = gray.shape\n",
    "    Sxx = np.zeros_like(gray, dtype=np.float32)\n",
    "    Syy = np.zeros_like(gray, dtype=np.float32)\n",
    "    Sxy = np.zeros_like(gray, dtype=np.float32)\n",
    "\n",
    "    for y in range(offset, height - offset):\n",
    "        for x in range(offset, width - offset):\n",
    "            Sxx[y, x] = np.sum(Ix2[y - offset:y + offset + 1, x - offset:x + offset + 1])\n",
    "            Syy[y, x] = np.sum(Iy2[y - offset:y + offset + 1, x - offset:x + offset + 1])\n",
    "            Sxy[y, x] = np.sum(Ixy[y - offset:y + offset + 1, x - offset:x + offset + 1])\n",
    "\n",
    "    # Compute the determinant and trace of the structure tensor\n",
    "    det = (Sxx * Syy) - (Sxy ** 2)\n",
    "    trace = Sxx + Syy\n",
    "\n",
    "    # Compute the corner response function\n",
    "    k = 0.04\n",
    "    response = det - k * (trace ** 2)\n",
    "\n",
    "    # Threshold the corner response function\n",
    "    threshold = 0.01 * response.max()\n",
    "    corners = np.argwhere(response > threshold)\n",
    "\n",
    "    # Draw crosses at the detected corners on the image\n",
    "    for corner in corners:\n",
    "        x, y = corner\n",
    "        size = 1\n",
    "        color = (0, 0, 255)\n",
    "        cv2.line(img, (y - size, x), (y + size, x), color, 2)\n",
    "        cv2.line(img, (y, x - size), (y, x + size), color, 2)\n",
    "\n",
    "    # Show the image with detected corners\n",
    "    cv2.imshow(\"Corners Detected\", img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def harris_corner_detection(image, block_size=3, ksize=3, k=0.04, threshold=0.06):\n",
    "    # Convert the input image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the derivatives of the image using the Sobel operator\n",
    "    Ix = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    Iy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "\n",
    "    # Compute the products of derivatives at each pixel\n",
    "    Ix2 = Ix ** 2\n",
    "    Iy2 = Iy ** 2\n",
    "    Ixy = Ix * Iy\n",
    "\n",
    "    # Compute the sum of products of derivatives over a local window\n",
    "    if ksize % 2 == 0 or ksize < 1:\n",
    "        raise ValueError(\"Invalid ksize parameter.\")\n",
    "    Sx2 = cv2.boxFilter(Ix2, cv2.CV_64F, (ksize, ksize))\n",
    "    Sy2 = cv2.boxFilter(Iy2, cv2.CV_64F, (ksize, ksize))\n",
    "    Sxy = cv2.boxFilter(Ixy, cv2.CV_64F, (ksize, ksize))\n",
    "\n",
    "    # Compute the Harris response for each pixel\n",
    "    det = (Sx2 * Sy2) - (Sxy ** 2)\n",
    "    trace = Sx2 + Sy2\n",
    "    response = det - k * (trace ** 2)\n",
    "\n",
    "    # Threshold the response to obtain candidate corners\n",
    "    response[response < threshold * response.max()] = 0\n",
    "\n",
    "    # Find the coordinates of the remaining corners\n",
    "    coords = np.argwhere(response > 0)\n",
    "    coords = [tuple(coord[::-1]) for coord in coords]\n",
    "\n",
    "    # Draw circles around the detected corners\n",
    "    for corner in coords:\n",
    "        cv2.circle(image, corner, 3, (0, 255, 0), -1)\n",
    "\n",
    "    # Display the image with detected corners\n",
    "    cv2.imshow('Harris Corner Detection', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return coords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_descriptor(img, corners):\n",
    "    patch_size = 16\n",
    "    subregion_size = 8\n",
    "    num_bins = 8\n",
    "    eps = 1e-5\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    height, width = gray.shape\n",
    "\n",
    "    # Compute the gradient magnitude and orientation for the entire image\n",
    "    dx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    dy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    mag = np.sqrt(dx**2 + dy**2)\n",
    "    ang = np.arctan2(dy, dx)\n",
    "\n",
    "    descriptors = []\n",
    "    for corner in corners:\n",
    "        x, y = corner\n",
    "\n",
    "        # Extract the patch centered at the corner point\n",
    "        x1 = max(0, x - patch_size//2)\n",
    "        x2 = min(width-1, x + patch_size//2)\n",
    "        y1 = max(0, y - patch_size//2)\n",
    "        y2 = min(height-1, y + patch_size//2)\n",
    "        patch = mag[y1:y2, x1:x2]\n",
    "        patch_ang = ang[y1:y2, x1:x2]\n",
    "\n",
    "        # Divide the patch into subregions and compute histograms of gradient orientations\n",
    "        desc = []\n",
    "        for i in range(patch.shape[0]//subregion_size):\n",
    "            for j in range(patch.shape[1]//subregion_size):\n",
    "                subpatch = patch[i*subregion_size:(i+1)*subregion_size, j*subregion_size:(j+1)*subregion_size]\n",
    "                subpatch_ang = patch_ang[i*subregion_size:(i+1)*subregion_size, j*subregion_size:(j+1)*subregion_size]\n",
    "                hist, _ = np.histogram(subpatch_ang, bins=num_bins, range=(-np.pi, np.pi), weights=subpatch)\n",
    "                desc.extend(hist)\n",
    "        \n",
    "        # Normalize the descriptor to be invariant to changes in illumination, contrast, and scale\n",
    "        desc = np.array(desc)\n",
    "        desc = desc / (np.linalg.norm(desc) + eps)\n",
    "\n",
    "        descriptors.append(desc)\n",
    "    #print(descriptors[0])\n",
    "\n",
    "    return descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_matching(desc1, desc2, threshold=0.5):\n",
    "    matches = []\n",
    "    for i, d1 in enumerate(desc1):\n",
    "        best_match = None\n",
    "        best_distance = float('inf')\n",
    "        for j, d2 in enumerate(desc2):\n",
    "            distance = 0\n",
    "            for k in range(min(len(d1), len(d2))):\n",
    "                distance += np.sum((d1[k] - d2[k]) ** 2)\n",
    "            if distance < best_distance:\n",
    "                best_distance = distance\n",
    "                best_match = j\n",
    "        if best_distance < threshold:\n",
    "            matches.append((i, best_match))\n",
    "\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(img1, features1, img2, features2, matches):\n",
    "    matched_img = np.hstack((img1, img2))\n",
    "\n",
    "    for m in matches:\n",
    "        pt1 = tuple(map(int, features1[m[0]]))\n",
    "        pt2 = tuple(map(int, features2[m[1]]))\n",
    "        cv2.line(matched_img, pt1, (pt2[0] + img1.shape[1], pt2[1]), (0, 255, 0), 1)\n",
    "\n",
    "    return matched_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_homography(matches, k):\n",
    "    \"\"\"\n",
    "    Finds the homography matrix using Direct Linear Transformation (DLT) algorithm.\n",
    "    Inputs:\n",
    "        - matches: a list of matching feature points, each point is a tuple of (x, y) coordinates.\n",
    "        - k: number of iterations for RANSAC algorithm.\n",
    "    Outputs:\n",
    "        - H: the homography matrix.\n",
    "    \"\"\"\n",
    "    # Convert the feature points to homogeneous coordinates\n",
    "    src_pts = np.ones((len(matches), 3))\n",
    "    dst_pts = np.ones((len(matches), 3))\n",
    "    for i, match in enumerate(matches):\n",
    "        src_pts[i, :2] = match[0]\n",
    "        dst_pts[i, :2] = match[1]\n",
    "\n",
    "    # Normalize the coordinates to improve numerical stability\n",
    "    src_pts[:, :2] /= src_pts[:, 2, None]\n",
    "    dst_pts[:, :2] /= dst_pts[:, 2, None]\n",
    "\n",
    "    # RANSAC algorithm to remove outliers\n",
    "    best_inliers = []\n",
    "    for i in range(k):\n",
    "        # Randomly select four pairs of matching points\n",
    "        indices = np.random.choice(len(matches), 4, replace=False)\n",
    "        src = src_pts[indices]\n",
    "        dst = dst_pts[indices]\n",
    "\n",
    "        # Compute the homography matrix using DLT algorithm\n",
    "        A = np.zeros((8, 9))\n",
    "        for j in range(4):\n",
    "            A[j*2, :3] = src[j]\n",
    "            A[j*2, 6:] = -dst[j, 0] * src[j]\n",
    "            A[j*2+1, 3:6] = src[j]\n",
    "            A[j*2+1, 6:] = -dst[j, 1] * src[j]\n",
    "        _, _, V = np.linalg.svd(A)\n",
    "        H = V[-1, :].reshape((3, 3))\n",
    "\n",
    "        # Compute the inliers\n",
    "        inliers = []\n",
    "        for j, match in enumerate(matches):\n",
    "            x1 = src_pts[j]\n",
    "            x2 = dst_pts[j]\n",
    "            x2_hat = H @ x1\n",
    "            x2_hat /= x2_hat[2]\n",
    "            if np.linalg.norm(x2 - x2_hat) < 5:\n",
    "                inliers.append(j)\n",
    "\n",
    "        # Update the best set of inliers\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "\n",
    "    # Refit the homography matrix using all inliers\n",
    "    src = src_pts[best_inliers]\n",
    "    dst = dst_pts[best_inliers]\n",
    "    A = np.zeros((2*len(src), 9))\n",
    "    for i in range(len(src)):\n",
    "        A[2*i, :3] = src[i]\n",
    "        A[2*i, 6:] = -dst[i, 0] * src[i]\n",
    "        A[2*i+1, 3:6] = src[i]\n",
    "        A[2*i+1, 6:] = -dst[i, 1] * src[i]\n",
    "    _, _, V = np.linalg.svd(A)\n",
    "    H = V[-1, :].reshape((3, 3))\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_matching(matches, homography_matrix, threshold=5.0):\n",
    "    good_matches = []\n",
    "    for match in matches:\n",
    "        pt1 = np.array([match[0][0], match[0][1], 1]).reshape(-1, 1)\n",
    "        pt2 = np.array([match[1][0], match[1][1], 1]).reshape(-1, 1)\n",
    "        transformed_pt1 = homography_matrix @ pt1\n",
    "        transformed_pt1 /= transformed_pt1[2, 0]\n",
    "        distance = np.linalg.norm(transformed_pt1[:2, 0] - pt2[:2, 0])\n",
    "        if distance < threshold:\n",
    "            good_matches.append(match)\n",
    "    return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(img1, img2, matches, H):\n",
    "    # Get the size of the output image\n",
    "    h1, w1 = img1.shape[:2]\n",
    "    h2, w2 = img2.shape[:2]\n",
    "    corners = np.array([[0, 0, 1], [0, h2-1, 1], [w2-1, h2-1, 1], [w2-1, 0, 1]])\n",
    "    transformed_corners = np.dot(corners, H.T)\n",
    "    transformed_corners[:, 0] /= transformed_corners[:, 2]\n",
    "    transformed_corners[:, 1] /= transformed_corners[:, 2]\n",
    "    x_min = int(min(np.min(transformed_corners[:, 0]), 0))\n",
    "    y_min = int(min(np.min(transformed_corners[:, 1]), 0))\n",
    "    x_max = int(max(np.max(transformed_corners[:, 0]), w1))\n",
    "    y_max = int(max(np.max(transformed_corners[:, 1]), h1))\n",
    "    output_size = (x_max - x_min, y_max - y_min)\n",
    "\n",
    "    # Compute the translation matrix\n",
    "    T = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]])\n",
    "\n",
    "    # Create an empty output image\n",
    "    output = np.zeros((output_size[1], output_size[0], 3), dtype=np.uint8)\n",
    "\n",
    "    # Copy the first image onto the output image\n",
    "    output[-y_min:h1-y_min, -x_min:w1-x_min] = img1\n",
    "\n",
    "    # Warp the second image using the homography matrix\n",
    "    warped = cv2.warpPerspective(img2, T.dot(H), output_size)\n",
    "\n",
    "    # Copy the warped second image onto the output image\n",
    "    for i, match in enumerate(matches):\n",
    "        pt1 = np.array([int(match[0][0]), int(match[0][1])])\n",
    "        pt2 = np.array([int(match[1][0] - x_min), int(match[1][1] - y_min)])\n",
    "        output = cv2.line(output, tuple(pt1), tuple(pt2), (0, 255, 0), 1)\n",
    "    for y in range(output_size[1]):\n",
    "        for x in range(output_size[0]):\n",
    "            if np.any(warped[y, x]):\n",
    "                output[y, x] = warped[y, x]\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m     15\u001b[0m h \u001b[39m=\u001b[39m find_homography(matches, \u001b[39m1000\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m result \u001b[39m=\u001b[39m stitch_images(proj_array[\u001b[39m0\u001b[39;49m], proj_array[\u001b[39m1\u001b[39;49m], matches, h)\n\u001b[0;32m     17\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mwarped_img\u001b[39m\u001b[39m'\u001b[39m, result)\n\u001b[0;32m     18\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[134], line 29\u001b[0m, in \u001b[0;36mstitch_images\u001b[1;34m(img1, img2, matches, H)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39m# Copy the warped second image onto the output image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m i, match \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(matches):\n\u001b[1;32m---> 29\u001b[0m     pt1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mint\u001b[39m(match[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]), \u001b[39mint\u001b[39m(match[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m])])\n\u001b[0;32m     30\u001b[0m     pt2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39mint\u001b[39m(match[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m-\u001b[39m x_min), \u001b[39mint\u001b[39m(match[\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m y_min)])\n\u001b[0;32m     31\u001b[0m     output \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mline(output, \u001b[39mtuple\u001b[39m(pt1), \u001b[39mtuple\u001b[39m(pt2), (\u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    img_array = read_images(\"test_images\")\n",
    "    proj_array = cylindrical_warp(img_array, 900)\n",
    "    corners0 = harris_corner_detection(proj_array[0])\n",
    "    corners1 = harris_corner_detection(proj_array[1])\n",
    "    descriptors0 = feature_descriptor(proj_array[0], corners0)\n",
    "    descriptors1 = feature_descriptor(proj_array[1], corners1)\n",
    "    matches = feature_matching(descriptors0, descriptors1)\n",
    "\n",
    "    matched_img = draw_matches(proj_array[0], corners0, proj_array[1], corners1, matches)\n",
    "    cv2.imshow('matched_img', matched_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    h = find_homography(matches, 1000)\n",
    "    result = stitch_images(proj_array[0], proj_array[1], matches, h)\n",
    "    cv2.imshow('warped_img', result)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
